<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Choice under Uncertainty (Lecture 1e)</title>
    <meta charset="utf-8" />
    <meta name="author" content="Prof. Ben Bushong" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis.css" rel="stylesheet" />
    <link rel="stylesheet" href="EC404.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Choice under Uncertainty (Lecture 1e)
## EC404; Fall 2021
### Prof. Ben Bushong
### Last updated September 28, 2021

---



layout: true

&lt;div class="msu-header"&gt;&lt;/div&gt;
&lt;div style = "position:fixed; visibility: hidden"&gt;
`$$\require{color}\definecolor{yellow}{rgb}{1, 0.8, 0.16078431372549}$$`
`$$\require{color}\definecolor{orange}{rgb}{0.96078431372549, 0.525490196078431, 0.203921568627451}$$`
`$$\require{color}\definecolor{MSUgreen}{rgb}{0.0784313725490196, 0.52156862745098, 0.231372549019608}$$`
&lt;/div&gt;

&lt;script type="text/x-mathjax-config"&gt;
MathJax.Hub.Config({
  TeX: {
    Macros: {
      yellow: ["{\\color{yellow}{#1}}", 1],
      orange: ["{\\color{orange}{#1}}", 1],
      MSUgreen: ["{\\color{MSUgreen}{#1}}", 1]
    },
    loader: {load: ['[tex]/color']},
    tex: {packages: {'[+]': ['color']}}
  }
});
&lt;/script&gt;

&lt;style&gt;
.yellow {color: #FFCC29;}
.orange {color: #F58634;}
.MSUGreen {color: #14853B;}
&lt;/style&gt;







---


class: inverseMSU
name: Overview

# Today

###  **Our Outline:**

This space will be filled by week's end.

---

class: inverseMSU
# "Participation" Questions

1. Suzy is risk loving. She faces a lottery (100, .4; -100, .6). She is offered the opportunity to avoid this lottery by paying 15 dollars. Will she do it? 

(Yes / No / We need more information)

2. Alexandre has preferences according to prospect theory (with the three properties of the value function we previously discussed). He faces the same lottery. What will he do? 

(Pay $15 / Play the lottery / We need more information)

3. Roxanne is confused by the content in this course. However, Roxanne has not come to office hours. Is Roxanne making wise life decisions? 

(Yes / No / We need more information)

---
class: MSU
name: intro
# "Reinventing" Prospect Theory

In the next (two? one and a half?) lectures we will "discover" some problems with vanilla Prospect Theory.

--

We'll also introduce a bunch of "new" value functions.

`\(\dots\)` except the value functions aren't new

`\(\dots\)` and the discoveries were lurking in the back of your mind this whole time.

--

And we'll do a million exercises. This material is tricky.

---
class: MSU
# Köszegi &amp; Rabin (2006)

We'll follow the KR theory of reference-dependent utility with loss aversion.  (Except it's really just the **right** way to do Prospect Theory.)

Their innovations address two major issues ("loopholes"):

1. What determines the reference point?

2. When do people experience loss aversion, and what is the magnitude of this experience?

--

They address these issues by incorporating two novel features:

A person's reference point is her recent beliefs or expectations about outcomes.

Gain-loss utility is directly tied to the intrinsic utility from consumption --- so that a person experiences more gain-loss utility for goods that involve more consumption utility.

---
class: MSU
name: sec1
# Köszegi &amp; Rabin (2006)

### Model

Suppose there are `\(2\)` goods:

- Person chooses a vector `\((x_{A},x_{B})\)`.
- Reference point is a vector `\((r_{A},r_{B})\)`.

--

**Preferences:**

`$$\text{Total Utility } \equiv \text{ }\left[ \text{ }m_{A}(x_{A})\text{ }+ \text{ }n_{A}(x_{A}|r_{A})\text{ }\right]$$`
`$$\qquad \qquad \qquad \qquad  +\text{ }\left[ \text{ }m_{B}(x_{B})\text{ }+\text{ }n_{B}(x_{B}|r_{B})\text{ }\right]$$`

--

- `\(m_{A}(x_{A})\)` is intrinsic utility for good `\(A\)`, and `\(m_{B}(x_{B})\)` is intrinsic utility for good `\(B\)`.

- `\(n_{A}(x_{A}|r_{A})\)` is gain-loss utility for good `\(A\)`, and `\(n_{B}(x_{B}|r_{B})\)` is gain-loss utility for good `\(B\)`.


---
class: MSU
# Köszegi &amp; Rabin (2006)

How to formalize that gain-loss utility is directly tied to intrinsic utility:

Assume there exists a *universal gain-loss function* `\(\mu (z)\)` such that the gain-loss utilities are:

`$$v_{A}(x_{A}|r_{A}) =\mu \left( \text{ }m_{A}(x_{A})-m_{A}(r_{A})\text{ }\right)$$`

`$$v_{B}(x_{B}|r_{B}) =\mu \left( \text{ }m_{B}(x_{B})-m_{B}(r_{B})\text{ }\right)$$`

--

In general, `\(\mu (z)\)` takes form of the Kahneman-Tversky value function. But we'll focus on the "easy" case:

`$$\mu (z)=\{ \quad  \eta*z \quad  \text{if} \quad z \geq 0$$`
`$$\qquad \qquad \eta*\lambda*z \quad \text{if} \quad z\leq 0$$`


---
class: MSU 
# Köszegi &amp; Rabin (2006)

Example: Two goods, shoes ( `\(c\)` ) and money ( `\(w\)` ), with intrinsic utilities:

`$$m(c) = \theta * c$$`
`$$m(w) = w$$`

--

As with mugs, we can represent shoe utility in a 2x2 grid (see board)

---
class: MSU
# Köszegi &amp; Rabin (2006)

Consider the following choice problem:

- Suppose Bogi starts with 0 shoes and wealth `\(w\)`, and has the option to purchase a shoe for price `\(p\)`. How does Bogi behave as a function of expectations?

**Case 1:** Suppose you expect to buy a pair of shoes 
`\(\Longrightarrow\)` reference point is `\((r_{c}=1,r_{m}=w-p)\)` :

`$$\text{Utility(Buy)} = \left[ \theta +\eta 0\right] + \left[ (w-p)+\eta 0\right]$$`

`$$\text{Utility(Not)} = \left[ 0-\eta \lambda \theta \right] + \left[w+\eta p\right]$$`

--

`$$\text{Buy when Utility(Buy)} \geq \text{ Utility(Not)}\Longleftrightarrow p\leq \frac{1+\eta \lambda }{1+\eta }\theta$$`


---
class: MSU
# Köszegi &amp; Rabin (2006)

Consider the following choice problem:

- Suppose Bogi starts with 0 shoes and wealth `\(w\)`, and has the option to purchase a shoe for price `\(p\)`. How does Bogi behave as a function of expectations?

**Case 2:** Suppose you expect not to buy any shoes `\(\Longrightarrow\)` reference point is `\((r_{c}=0,r_{m}=w)\)` :

`$$\text{Utility(Buy)} = \left[ \theta +\eta \theta \right] + \left[ (w-p)-\eta \lambda p\right]$$`

`$$\text{Utility(Not)} = \left[ 0+\eta 0\right] + \left[ w+\eta 0 \right]$$`


`$$\text{Buy when Utility(Buy)}\geq \text{ Utility(Not)}\Longleftrightarrow p\leq \frac{1+\eta }{1+\eta \lambda }\theta$$`.

---
class: MSU
# Köszegi &amp; Rabin (2006)

Because `\(\lambda &gt;1\)` implies `\(\frac{1+\eta \lambda }{1+\eta }&gt;\frac{1+\eta }{1+\eta \lambda}\)`, there are three cases:


1. If `\(p&gt;\frac{1+\eta \lambda }{1+\eta }\theta\)`, don't buy no matter your beliefs.

--

2. If $p&lt;\frac{1+\eta }{1+\eta \lambda }\theta $, buy no matter your beliefs.

--

3. If `\(\frac{1+\eta }{1+\eta \lambda }\theta &lt;p&lt;\frac{1+\eta \lambda }{1+\eta }\theta\)`, buy if you expect to buy, and don't buy if you expect not to buy.

**Point:** If the reference point depends on expectations, then, even in the same situation, a person might exhibit different outcomes depending on which set of self-fulfilling expectations he happens to have.

---
# Köszegi &amp; Rabin (2006) Example

Suppose there are two goods, candy bars ($c$) and money ($m$). Paige has initial income `\(I\)`, and she is deciding whether to buy 0, 1, or 2 candy bars at a price of `\(p\)` per candy bar. Paige's total utility is the sum of her candy-bar utility and her money utility, and her intrinsic utilities for the two goods are:

`$$w_{c}(c) \equiv &amp;\left\{ 0 \text{if }c=0$$`
`$$\qquad \theta _{1}  \text{if }c=1$$`
`$$\qquad \theta _{1}+\theta _{2} &amp; \text{if }c=2$$`

`$$\qquad \qquad \text{where }\theta _{1}&gt;\theta _{2} \text{and } w_{m}(m) &amp;\equiv m$$`

---
class
# Köszegi &amp; Rabin (2006) Deterministic Example}

**(a)** If Paige were a standard agent who only cares about her intrinsic utilities, how would she behave as a function of the price `\(p\)`? In other words, for what prices would she buy zero candy bars, for what prices would she buy one candy bar, and for what prices would she buy two candy bars?

**(b)** Now suppose that Paige behaves according to the Koszegi-Rabin model. In other words, in addition to intrinsic utilities, she also cares about gain-loss utility, where the gain-loss utility for each good is derived from the universal gain-loss function described above.

If Paige expects to buy no candy bars, how would she behave as a function of the price `\(p\)`? In other words, for what prices would she buy zero candy bars, for what prices would she buy one candy bar, and for what prices would she buy two candy bars?

---
class: MSU
name: sec2
# Köszegi &amp; Rabin (2007)

In a second paper, Köszegi and Rabin investigate the implications of their approach for basic risk preferences.

Assume one good, money ($x$), with intrinsic utility `\(w(x)=x\)`.

- Note: `\(w(x)=x\)` implies there is no intrinsic risk aversion --- all risk aversion will derive from gain-loss utility!

--

Applying their approach, if consume money `\(x\)` given reference point `\(r\)`, then total utility is

`$$u(x|r)=\left\{x+\eta (x-r) &amp; \text{if }x\geq r$$`
`$$\quad \quad x+\eta \lambda (x-r) &amp; \text{if }x\leq r$$`

---
class: MSU
# Köszegi &amp; Rabin (2007)

How to incorporate uncertainty:

- If consume lottery `\(X\equiv (x_{1},p_{1};...;x_{N},p_{N})\)` given reference point `\(r\)`, then "expected" total utility is

`$$U(X|r)\text{ }=\text{ }\sum_{i=1}^{N}\text{ }p_{i}\text{ }u(x_{i}|r)\text{.}$$`

--

**Example:** If `\(X=(200,\frac{1}{4};0,\frac{3}{4})\)` and `\(r=100\)`, then

`$$U(X|r)=\frac{1}{4}u(200|100)+\frac{3}{4}u(0|100).$$`

--

But might expect a lottery, in which case **the reference point would be a lottery**.

---
class: MSU
# Köszegi &amp; Rabin (2007)

If consume money `\(x\)` given reference point `\(R\equiv (r_{1},q_{1};...;r_{M},q_{M})\)`, then "expected" total utility is

`$$U(x|R)\text{ }=\text{ }\sum_{j=1}^{M}\text{ }q_{j}\text{ }u(x|r_{j})\text{.}$$`


---
class: MSU
# Köszegi &amp; Rabin (2007)

- If consume lottery `\(X\equiv (x_{1},p_{1};...;x_{N},p_{N})\)` given reference point `\(R\equiv (r_{1},q_{1};...;r_{M},q_{M})\)`, then total utility is

`$$U(X|R)\text{ } =\text{ }\sum_{i=1}^{N}\text{ }p_{i}\text{ }U(x_{i}|R)$$`
`$$=\text{ }\sum_{j=1}^{M}\text{ }q_{j}\text{ }U(X|r_{j})$$`
`$$=\text{ }\sum_{i=1}^{N}\text{ }\sum_{j=1}^{M}\text{ }p_{i}\text{ }q_{j}\text{ }u(x_{i}|r_{j})\text{.}$$`

---
ckass: MSU
# Köszegi &amp; Rabin (2007)

**Example:** If `\(X=(200,\frac{1}{4};0,\frac{3}{4})\)` and `\(R=(150,\frac{1}{3};50,\frac{2}{3})\)`, then


`$$U(X|R)=\frac{1}{4}\left[ \frac{1}{3}u(200|150)+\frac{2}{3}u(200|50)\right] + \frac{3}{4}\left[ \frac{1}{3}u(0|150)+\frac{2}{3}u(0|50)\right]$$`

or


`$$U(X|R)=\frac{1}{3}\left[ \frac{1}{4}u(200|150)+\frac{3}{4}u(0|150)\right] + \frac{2}{3}\left[ \frac{1}{4}u(200|50)+\frac{3}{4}u(0|50)\right]$$`

or

U(X|R)=\frac{1}{12}u(200|150)+\frac{1}{6}u(200|50)+\frac{1}{4}u(0|150)+\frac{1}{2}u(0|50)$$.

---

	# Köszegi &amp; Rabin (2007)}

	\textbf{Point 1:} Risk aversion when no possible "losses".



	Consider choice%
	\[
	A\equiv (y,1)\ \text{with }y\leq 100\qquad \text{vs.\qquad }B\equiv (\text{ }%
	200,\frac{1}{2}\text{ };\text{ }0,\frac{1}{2}\text{ })
	\]

	 %

	Case 1: Suppose expect lottery $A\Longrightarrow $ reference point is `\(r=y\)`:

	\begin{center}
		\begin{tabular}{llclc}
			&amp;  &amp;  &amp;  &amp;  \\
			`\(U(A|r)\)` &amp; `\(=\)` &amp; `\(y\)` &amp; `\(+\)` &amp; $\left[ 0\right] $ \\
			&amp;  &amp;  &amp;  &amp;  \\
			`\(U(B|r)\)` &amp; `\(=\)` &amp; `\(100\)` &amp; `\(+\)` &amp; $\left[ \frac{1}{2}\eta (200-y)+\frac{1}{2}%
			\eta \lambda (0-y)\right] $ \\
			&amp;  &amp;  &amp;  &amp;
		\end{tabular}

		\[
		\text{Choose }A\text{ if }y\geq \frac{1+\eta }{1+\frac{1}{2}\eta +\frac{1}{2}%
			\eta \lambda }100\equiv \bar{y}_{1}\text{.}
		\]
	\end{center}

	 % Note: `\(\lambda &gt;1\)` implies `\(\bar{y}_{1}&lt;100\)` --- risk averse!

	%TCIMACRO{\TeXButton{EndFrame}{---}}%
	%BeginExpansion
---%
%EndExpansion

%TCIMACRO{\TeXButton{BeginFrame}{}}%
%BeginExpansion
%
	%EndExpansion

	# Köszegi &amp; Rabin (2007)}

	Case 2: Suppose expect lottery $B\Longrightarrow $ reference point is
	\newline
	`\(R=(\)` `\(200,\frac{1}{2}\)` `\(;\)` `\(0,\frac{1}{2}\)` `\()\)`:

	\begin{center}
		\begin{tabular}{llclc}
			&amp;  &amp;  &amp;  &amp;  \\
			`\(U(A|R)\)` &amp; `\(=\)` &amp; `\(y\)` &amp; `\(+\)` &amp; $\left[ \frac{1}{2}\eta (y-0)+\frac{1}{2}\eta
			\lambda (y-200)\right] $ \\
			&amp;  &amp;  &amp;  &amp;  \\
			`\(U(B|r)\)` &amp; `\(=\)` &amp; `\(100\)` &amp; `\(+\)` &amp; $\frac{1}{2}\left[ \frac{1}{2}\eta (200-0)+%
			\frac{1}{2}\eta (200-200)\right] $ \\
			&amp;  &amp;  &amp; `\(+\)` &amp; $\frac{1}{2}\left[ \frac{1}{2}\eta (0-0)+\frac{1}{2}\eta
			\lambda (0-200)\right] $ \\
			&amp;  &amp;  &amp;  &amp;
		\end{tabular}
	\end{center}

	\[
	\text{Choose }A\text{ if }y\geq 100\equiv \bar{y}_{2}\text{.}
	\]

	 %

	Note: `\(\bar{y}_{2}&gt;\bar{y}_{1}\)` --- expecting risk makes you less risk
	averse!

	\begin{itemize}
		\item Intuition: When expect risk, even certain outcomes involve gains and
		losses, and thus they lose part of their advantage relative to risky
		outcomes.
	\end{itemize}

	%TCIMACRO{\TeXButton{EndFrame}{---}}%
	%BeginExpansion
---%
%EndExpansion

%TCIMACRO{\TeXButton{BeginFrame}{}}%
%BeginExpansion
%
	%EndExpansion

	# Köszegi &amp; Rabin (2007)}

	Point 2: Demand for insurance at actuarially unfair prices.



	Suppose you have wealth \$1000, but there is a 10\% chance that you will
	suffer a loss of \$250.



	Full insurance is available at price $\pi &gt;\$25$.

	\begin{itemize}
		\item If insure, face lottery `\((1000-\pi ,1)\equiv A\)`.

		\item If don't, face lottery `\((1000,.9;750,.1)\equiv B\)`.
	\end{itemize}

	\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}%
	\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}%
	\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}%
	\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}%
	\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}%
	\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}%
	\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}%
	\symbol{94}\symbol{94}\symbol{94}\symbol{94}

	Note: If reference point is `\(r=1000\)`, don't insure!

	\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}%
	\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}%
	\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}%
	\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}%
	\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}%
	\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}%
	\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}\symbol{94}%
	\symbol{94}\symbol{94}\symbol{94}\symbol{94}



	Could it be that you expect to be insured, and still prefer to be insured?



	In other words, given reference point $r=1000-\pi $, do you prefer lottery $%
	A\equiv (1000-\pi ,1)$ over `\(B\equiv (1000,.9;750,.1)\)`?

	%TCIMACRO{\TeXButton{EndFrame}{---}}%
	%BeginExpansion
---%
%EndExpansion

%TCIMACRO{\TeXButton{BeginFrame}{}}%
%BeginExpansion
%
	%EndExpansion

	# Köszegi &amp; Rabin (2007)}

	In other words, given reference point $r=1000-\pi $, do you prefer lottery $%
	A\equiv (1000-\pi ,1)$ over `\(B\equiv (1000,.9;750,.1)\)`?

	\begin{center}
		\begin{tabular}{ccccc}
			&amp;  &amp;  &amp;  &amp;  \\
			`\(U(A|r)\)` &amp; `\(=\)` &amp; $\left[ 1000-\pi \right] $ &amp; `\(+\)` &amp; $\left[ 0\right] $ \\
			&amp;  &amp;  &amp;  &amp;  \\
			`\(U(B|r)\)` &amp; `\(=\)` &amp; `\(975\)` &amp; `\(+\)` &amp; $\left[ .9\eta (\pi )+.1\eta \lambda (\pi
			-250)\right] $ \\
			&amp;  &amp;  &amp;  &amp;
		\end{tabular}
	\end{center}

	\[
	\text{Insure if }\pi \leq \frac{1+\eta \lambda }{1+\eta \lambda -.9\eta
		(\lambda -1)}25\equiv \bar{\pi}
	\]



	Note: `\(\lambda &gt;1\)` implies `\(\bar{\pi}&gt;25\)` --- indeed willing to insure at
	actuarially unfair prices.

	\begin{itemize}
		\item Intuition: Because expect to pay premium, it's not felt as a loss.
	\end{itemize}

	%TCIMACRO{\TeXButton{EndFrame}{---}}%
	%BeginExpansion
---%
%EndExpansion

%TCIMACRO{\TeXButton{BeginFrame}{}}%
%BeginExpansion
%
	%EndExpansion

	# Application: Labor Supply of Taxicab Drivers}

	\underline{Camerer, Babcock, Loewenstein, &amp; Thaler (1997)}

	\vspace*{.2in}

	\begin{itemize}
		\item For many jobs, people choose how to allocate their labor from
		day-to-day, or from week-to-week, or from month-to-month.



		\item Benchmark: The standard life-cycle model of labor supply says that, if
		your wage varies over time, you should work more when the wage is high than
		you do when the wage is low.

		\begin{itemize}
			\item Simple intuition: efficiently allocate your work effort.
		\end{itemize}



		\item They test this prediction on NYC cab drivers.
	\end{itemize}

	%TCIMACRO{\TeXButton{EndFrame}{---}}%
	%BeginExpansion
---%
%EndExpansion

%TCIMACRO{\TeXButton{BeginFrame}{}}%
%BeginExpansion
%
	%EndExpansion

	# Camerer, Babcock, Loewenstein, &amp; Thaler (1997)}

	First finding: Their data permits them to calculate an average hourly wage
	for cab drivers, and they conclude that wages are highly correlated within a
	day, but not correlated across days.

	\vspace*{.25in}

	Hence, they take their unit of observation to be a day --- in particular,
	they estimate a daily wage equation:%
	\[
	\ln H_{t}=\gamma \ln W_{t}+\beta X_{t}+\varepsilon _{t}
	\]

	\begin{itemize}
		\item $H_{t}\equiv $ hours worked on day `\(t\)`

		\item $W_{t}\equiv $ average wage on day `\(t\)`
	\end{itemize}

	\vspace*{.25in}

	Standard model predicts `\(\gamma &gt;0\)`, but they find `\(\gamma &lt;0\)`.



	In words, the standard model predicts positive wage elasticities, but they
	find negative wage elasticities.

	%TCIMACRO{\TeXButton{EndFrame}{---}}%
	%BeginExpansion
---%
%EndExpansion

%TCIMACRO{\TeXButton{BeginFrame}{}}%
%BeginExpansion
%
	%EndExpansion

	# Camerer, Babcock, Loewenstein, &amp; Thaler (QJE 1997)}

	Their explanation is income targeting driven by loss aversion:

	\begin{itemize}
		\item one-day time horizon for decision making.

		\item reference point is a daily income target.

		\item losses relative to the target loom larger than gains.
	\end{itemize}

	%TCIMACRO{\TeXButton{EndFrame}{---}}%
	%BeginExpansion
---%
%EndExpansion

%TCIMACRO{\TeXButton{BeginFrame}{}}%
%BeginExpansion
%
	%EndExpansion

	# Farber (JPE 2005)}

	\underline{Farber (\emph{JPE} 2005)}



	He first provides several critiques of Camerer et al (\emph{QJE} 1997):

	\begin{itemize}
		\item There is a \textquotedblleft division bias\textquotedblright\ ---
		Camerer et al attempt to correct for it, but there are good reasons to doubt
		their correction.

		\begin{itemize}
			\item "Division bias": wages are calculated as earnings divided by hours, but hours are endogenous.

			\item[$\rightarrow$] Negative bias in wage elasticity estimates.
		\end{itemize}

		\item After cutting the data in a different way, he finds that it is not so
		clear there is more inter-day variation in the wage than intra-day variation
		in the wage.
	\end{itemize}

	\vspace*{0.1in}

	Main point: There is a better approach that gets around these problems:
	instead of estimating usual wage regressions, estimate a probit
	optimal-stopping model.

	%TCIMACRO{\TeXButton{EndFrame}{---}}%
	%BeginExpansion
---%
%EndExpansion

%TCIMACRO{\TeXButton{BeginFrame}{}}%
%BeginExpansion
%
	%EndExpansion

	# Farber (JPE 2005)}

	[And now for a little econometrics!]

	\vspace*{0.1in}

	Probit optimal-stopping model:

	\begin{itemize}
		\item Stop when `\(R(\tau )\geq 0\)`, where $R(\tau )=\gamma _{1}h_{\tau
		}+\gamma _{2}y_{\tau }+\beta X_{\tau }+\varepsilon _{\tau }$.

		\begin{itemize}
			\item $h_{\tau }\equiv $ hours worked today after trip $\tau $

			\item $y_{\tau }\equiv $ earnings today after trip $\tau $
		\end{itemize}
	\end{itemize}



	\begin{itemize}
		\item Standard model predicts `\(\gamma _{1}&gt;0\)` and `\(\gamma _{2}=0\)`.
	\end{itemize}

	%TCIMACRO{\TeXButton{EndFrame}{---}}%
	%BeginExpansion
---%
%EndExpansion

%TCIMACRO{\TeXButton{BeginFrame}{}}%
%BeginExpansion
%
	%EndExpansion

	# Farber (JPE 2005)}

	\begin{itemize}
		\item He indeed finds evidence consistent with `\(\gamma _{1}&gt;0\)` and $\gamma
		_{2}=0$, as in the standard model.
	\end{itemize}

	\vspace*{.2in}

	\begin{itemize}
		\item BUT it's not clear whether this result is inconsistent with income
		targeting.

		\begin{itemize}
			\item Income targeting does not imply `\(\gamma _{1}=0\)`.

			\item Perhaps a misspecification of the daily-income effect.
		\end{itemize}
	\end{itemize}

	%TCIMACRO{\TeXButton{EndFrame}{---}}%
	%BeginExpansion
---%
%EndExpansion

%TCIMACRO{\TeXButton{BeginFrame}{}}%
%BeginExpansion
%
	%EndExpansion

	# Crawford &amp; Meng (AER 2011)}

	\underline{Crawford &amp; Meng (AER 2011)}

	\vspace*{.2in}

	They apply the Köszegi-Rabin perspective to this debate:

	\begin{itemize}
		\item There should be gain-loss utility over each dimension of consumption
		--- here, this means over income (as usual) but also over hours worked.



		\item Take the reference point to be people's expectations about outcomes
		--- in particular, take them to be people's average experienced outcomes.
	\end{itemize}

	%TCIMACRO{\TeXButton{EndFrame}{---}}%
	%BeginExpansion
---%
%EndExpansion

%TCIMACRO{\TeXButton{BeginFrame}{}}%
%BeginExpansion
%
	%EndExpansion

	# Crawford &amp; Meng (AER 2011)}

	Define:
	\begin{tabular}[t]{l}
		$H_{t}\equiv $ hours worked on day `\(t\)` \\
		$Y_{t}\equiv $ income on day `\(t\)` \\
		`\(W_{t}\equiv Y_{t}/H_{t}\)` \\
		\\
		$H^{e}\equiv $ average of `\(H_{t}\)` \\
		$Y^{e}\equiv $ average of `\(Y_{t}\)` \\
		`\(W^{e}\equiv Y^{e}/H^{e}\)`
	\end{tabular}

	\vspace*{0.25in}

	Their Hypothesis: Reference point is `\((H^{e},Y^{e})\)`.

	\begin{itemize}
		\item Working fewer than `\(H^{e}\)` hours generates gain utility, and working
		more than `\(H^{e}\)` hours generates loss utility.

		\item Earning more than income `\(Y^{e}\)` generates gain utility, and earning
		less than income `\(Y^{e}\)` generates loss utility.
	\end{itemize}

	%TCIMACRO{\TeXButton{EndFrame}{---}}%
	%BeginExpansion
---%
%EndExpansion

%TCIMACRO{\TeXButton{BeginFrame}{}}%
%BeginExpansion
%
	%EndExpansion

	# Crawford &amp; Meng (AER 2011)}

	Key Idea:

	\begin{itemize}
		\item On high-wage days ($W_{t}&gt;W^{e}$), hit `\(Y^{e}\)` first and `\(H^{e}\)`
		second.

		\item On low-wage days ($W_{t}&lt;W^{e}$), hit `\(H^{e}\)` first and `\(Y^{e}\)` second.
	\end{itemize}

	\vspace*{0.3in}

	This suggests splitting the sample into high-wage days vs. low-wage days,
	because this model predicts that we should see different patterns of
	behavior.



	Hence, Crawford &amp; Meng re-run the Farber (2005) estimation (with Farber's
	dataset), except they split the dataset into observations on
	\textquotedblleft high-wage days\textquotedblright\ vs. \textquotedblleft
	low-wage days\textquotedblright .

	%TCIMACRO{\TeXButton{EndFrame}{---}}%
	%BeginExpansion
---%
%EndExpansion

%TCIMACRO{\TeXButton{BeginFrame}{}}%
%BeginExpansion
%
	%EndExpansion

	# Crawford &amp; Meng (AER 2011)}

	Recall that the Farber (2005) model is:

	\begin{itemize}
		\item Stop when `\(R(\tau )\geq 0\)`, where $R(\tau )=\gamma _{1}h_{\tau
		}+\gamma _{2}y_{\tau }+\beta X_{\tau }+\varepsilon _{\tau }$
	\end{itemize}

	Note: The predicted pattern of behavior depends on whether stopping
	typically closer to when hit first or second reference point.

	\begin{itemize}
		\item If stopping closer to first reference point, model predicts:

		\begin{itemize}
			\item For high-wage days, `\(\gamma _{2}&gt;0\)` while `\(\gamma _{1}=0\)`.

			\item For low-wage days, `\(\gamma _{1}&gt;0\)` while `\(\gamma _{2}=0\)`.
		\end{itemize}

		\item If stopping closer to second reference point, model predicts:

		\begin{itemize}
			\item For high-wage days, `\(\gamma _{1}&gt;0\)` while `\(\gamma _{2}=0\)`.

			\item For low-wage days, `\(\gamma _{2}&gt;0\)` while `\(\gamma _{1}=0\)`.
		\end{itemize}
	\end{itemize}

	Standard model predicts `\(\gamma _{1}&gt;0\)` while `\(\gamma _{2}=0\)` for either
	case.

	%TCIMACRO{\TeXButton{EndFrame}{---}}%
	%BeginExpansion
---%
%EndExpansion

%TCIMACRO{\TeXButton{BeginFrame}{}}%
%BeginExpansion
%
	%EndExpansion

	# Crawford &amp; Meng (AER 2011)}

	They find evidence consistent with their model and strongly reject Farber's analysis.



	Moreover, they show that targets in hours loom larger than targets in wages, which is consistent with the theory.

	%TCIMACRO{\TeXButton{EndFrame}{---}}%
	%BeginExpansion
---%



# Other Empirical Work}

Crawford and Meng (2011) and its predecessors have been influential because of the domain: labor supply. However, this domain can make the analysis more complex than it needs to be.

\vspace*{0.1in}

An alternative approach (innovated by Saez 2010; and Chetty et. al 2011): search for excess "bunching".

\begin{itemize}
	\item Observed distribution of data exceeds a modeled counterfactual distribution or a normative distribution.

	\vspace*{0.1in}

	\item Chetty et al. (2011) application: taxes and kinks in the tax schedule.
\end{itemize}

Allen et al. (2017) looks for this in marathon runners.

---



# Allen et al. 2017}

\begin{center}
\begin{figure}
	\includegraphics[scale=.55]{graphics/allenetal2017_1}
\end{figure}
\end{center}

---





# Allen et al. 2017}

\begin{center}
\begin{figure}
\includegraphics[scale=.33]{graphics/allenetal2017_2}
\end{figure}
\end{center}

---




# Reference-Dependent Welfare}

\dots not \textbf{that} kind of welfare. The economics kind.

\vspace*{0.1in}

Put more concretely: are people worse off for having made risk averse decisions?

\begin{itemize}
\item Samuelson showed us that they are worse of mathematically.

\vspace*{0.1in}

\item Ultimately, answer to this question depends on modeler's beliefs about whether loss aversion is something that people really \textit{feel}, or merely an artifact of some choice bias or mistake.

\item Two camps: (1) Loss aversion is an affective forecasting error; (2) Loss aversion is a real manifestation of preferences.
\end{itemize}

Surprisingly: Kahneman waffles between two; see e.g. Schkade and Kahneman (1998).

\vspace*{0.1in}

\alert{Me:} (2.5) Loss aversion is a little bit an affective forecasting error and a little bit "real".

---



# Epilogue}

What have we learned in `\(\approx 500\)` years of studying risk preferences?

\vspace*{0.1in}

\textbf{Expected values} matter, but don't wholly determine choice.

\begin{itemize}
\item \dots except they probably \textit{should}. [Begin rant.]

\vspace*{0.1in}

\item \dots most of the time. [End rant.]
\end{itemize}

\vspace*{0.1in}

\textbf{Diminishing marginal utility} matters, but definitely does not explain most choices over risk.

\begin{itemize}
\item \dots and I'm suspicious of \textit{all} evidence on diminishing marginal utility of wealth.

\item Evidence conflated with reference-point effects (e.g. hedonic treadmill).
\end{itemize}

---


# Epilogue}

\textbf{Prospect Theory} matters, but you need to apply it correctly.

\begin{itemize}
\item Misleading conclusions when you fail to account for beliefs.

\vspace*{0.1in}

\item \dots  but when you apply the "correct model", your intuitions are preserved.
\end{itemize}

\vspace*{0.1in}

BUT: there are a lot of open questions about Köszegi and Rabin's theory.

\indent (Wanna go to grad school?)

---



# Epilogue}

We've also (sneakily) introduced a new category of utility function:\textbf{ belief-based utility}.



We will return to some other models in this space.

\begin{itemize}
\item \dots and in doing so we can address the lingering question: what \textit{is} the reference point?
\end{itemize}

---

%EndExpansion

\end{document}
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
